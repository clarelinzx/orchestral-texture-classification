{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145018f9",
   "metadata": {},
   "source": [
    "This is a pseudo code for training simple deep models at a glance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b17f56",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('device = ', device)\n",
    "\n",
    "from data_processing.PianoRollsDataset import PianoRollsDataset\n",
    "from models.utils import get_class_weight_for_perf, draw_3_fig, draw_test_on, print_confusion_matrix, get_class_weight, get_num_params\n",
    "from models.deep_models import CnnModel, BilstmModel, CrnnModel, Transformer\n",
    "from models.trainer import MySingleClassTrainer\n",
    "from settings.annotations import LABEL_DCT\n",
    "from settings.evaluation import PERFORMANCE_DF_COLS\n",
    "from settings.s3_info import file_path as s3_file_path\n",
    "from settings.s3_info import int_to_string as piece_name_in_str_s3\n",
    "from settings.s3_info import meta_csv_path as meta_csv_file_s3\n",
    "from settings.orchestration_info import file_path as orchestration_file_path\n",
    "from settings.orchestration_info import int_to_string as piece_name_in_str\n",
    "from settings.orchestration_info import meta_csv_path as meta_csv_file\n",
    "\n",
    "converted_path = {\n",
    "    's3': s3_file_path,\n",
    "    'orchestration': orchestration_file_path\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696aa493",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12ff5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = '2025-06-03_40-COMB-1-5'\n",
    "save_at = os.path.join('.', 'results', experiment_name)\n",
    "print(f\"{save_at = }\")\n",
    "use_model = 'cnn'  # [\"cnn\", \"lstm\", \"crnn\"]\n",
    "BLEND_MODE = 'COMB'  # [\"SINGLE\", \"SUM\", \"COMB\"]\n",
    "k = 5                # if BLEND_MODE is 'COMB'\n",
    "dropout = 0\n",
    "num_layers = 1\n",
    "exp_dict = {  # Determine how many information is fed to a model\n",
    "    0: {\n",
    "        'add_inst': 'target_inst',  # instruments name: [None, 'target_inst']\n",
    "        'add_barlines': True,       # bar line positions\n",
    "        'add_replaymtx':  True}     # replay matrix denoting the onset time of each note event (like a piano roll)\n",
    "}\n",
    "exp_id = 0\n",
    "add_inst = exp_dict[exp_id]['add_inst']\n",
    "add_barlines = exp_dict[exp_id]['add_barlines']\n",
    "add_replaymtx = exp_dict[exp_id]['add_replaymtx']\n",
    "print(f\"Running experiment {exp_id} with parameters: {add_inst=}, {add_barlines=}, {add_beats=}, {add_rest=}, {add_replaymtx=}\")\n",
    "\n",
    "is_debug = True\n",
    "k_fold = False\n",
    "pretrained = None\n",
    "PATIENT = 10\n",
    "threshold = 0.5\n",
    "BATCH_SIZE = 512\n",
    "epoch_beg = 0\n",
    "epoch_end = 2 if is_debug else 1\n",
    "CONTEXT_MEASURES = 1 # i.e., \"m\" in paper\n",
    "OTHER_INST = True # if OTHER_INST is True:\n",
    "                    # 'SUM': sum all tracks => 2 channels, \n",
    "                    # 'COMB': choose k-1 other trakcs => k channels\n",
    "\n",
    "# Calculate the number of input channels, because this number depends on \n",
    "# how many information a model is fed to\n",
    "if OTHER_INST:\n",
    "    if BLEND_MODE=='SUM': \n",
    "        input_ch = 2\n",
    "        if add_replaymtx:\n",
    "            input_ch += 2\n",
    "    elif BLEND_MODE=='COMB': \n",
    "        input_ch = k\n",
    "        if add_replaymtx:\n",
    "            input_ch += k \n",
    "else:\n",
    "    input_ch = 1\n",
    "    if add_replaymtx:\n",
    "        input_ch += 1\n",
    "if add_inst=='target_inst':\n",
    "    input_ch += 1\n",
    "elif add_inst=='all':\n",
    "    if BLEND_MODE=='COMB':\n",
    "        input_ch += k\n",
    "    elif BLEND_MODE=='SUM':\n",
    "            input_ch += 2\n",
    "    else:\n",
    "        input_ch += 1\n",
    "if add_barlines:\n",
    "    input_ch += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bc5071",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "Split the Orchestration dataset into training set, valid set, and testing set. \n",
    "\n",
    "The pieces used for testing set are first movement from Mozart's k. 504, Haydn's hob. 99, and Beethoven's Op. 21.\n",
    "\n",
    "The rest pieces are further randomized and splited with the ratio of 8:2 to form training set and valid set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0356e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pieces_idx = [0, 4, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348fd16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = PianoRollsDataset(\n",
    "    meta_csv_file, test=False,\n",
    "    test_piece=test_pieces_idx,\n",
    "    context=CONTEXT_MEASURES,\n",
    "    other_inst=OTHER_INST,\n",
    "    blend=BLEND_MODE,\n",
    "    k=k,\n",
    "    add_inst=add_inst,\n",
    "    add_barlines=add_barlines,\n",
    "    add_replaymtx=add_replaymtx,\n",
    "    converted_path=converted_path,\n",
    "    ds='orchestration',\n",
    ")\n",
    "test_set = PianoRollsDataset(\n",
    "    meta_csv_file,\n",
    "    test=True,\n",
    "    test_piece=test_pieces_idx,\n",
    "    context=CONTEXT_MEASURES,\n",
    "    other_inst=OTHER_INST,\n",
    "    blend=BLEND_MODE,\n",
    "    k=k,\n",
    "    add_inst=add_inst,\n",
    "    add_barlines=add_barlines,\n",
    "    add_replaymtx=add_replaymtx,\n",
    "    converted_path=converted_path,\n",
    "    ds='orchestration',\n",
    ")\n",
    "train_size = int(0.8 * len(train_set)) \n",
    "valid_size = len(train_set) - train_size\n",
    "train_subset, valid_subset = random_split(train_set, [train_size, valid_size])\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd17c2f6",
   "metadata": {},
   "source": [
    "## Models\n",
    "Create a model and calculate its size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf973c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_model=='cnn':\n",
    "    model = CnnModel(\n",
    "        input_channels=input_ch,\n",
    "        context_measures=CONTEXT_MEASURES,\n",
    "    )\n",
    "elif use_model=='lstm':\n",
    "    model = BilstmModel(\n",
    "        input_channels=input_ch,\n",
    "        context_measures=CONTEXT_MEASURES,\n",
    "        dropout=dropout,\n",
    "        num_layers=num_layers,\n",
    "    )\n",
    "elif use_model=='crnn':\n",
    "    model = CrnnModel(\n",
    "        input_channels=input_ch,\n",
    "        context_measures=CONTEXT_MEASURES,\n",
    "    )\n",
    "elif use_model=='transformer':\n",
    "    model = Transformer(\n",
    "    input_channels=input_ch,\n",
    ")\n",
    "if pretrained is not None:\n",
    "    model.load_state_dict(torch.load(pretrained))\n",
    "\n",
    "print(model.parameters())\n",
    "\n",
    "class_count_train, class_weight_train = get_class_weight(train_set)\n",
    "tmp = np.zeros(3)\n",
    "for _ in range(8):\n",
    "    tmp += class_weight_train[str(_)] * np.array(LABEL_DCT[_]['label'])\n",
    "class_weight_train = [_/sum(tmp) for _ in tmp]\n",
    "loss_func = torch.nn.BCELoss(\n",
    "    weight=torch.tensor(class_weight_train, dtype=torch.float16).to(device)\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c384dd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dflst, total_params, total_params_nograd = get_num_params(model, [], 0, 0)\n",
    "df = pd.DataFrame(dflst)\n",
    "print(f\"{total_params=}, {total_params_nograd=}\")\n",
    "df.to_csv(f'{save_at}/model_params.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cbdbcf",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedbc3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need class weight during evaluaing the performace for each epoch\n",
    "class_count, class_weight = get_class_weight_for_perf(train_set)\n",
    "trainer = MySingleClassTrainer(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=None,\n",
    "        epoch_beg=epoch_beg,\n",
    "        epoch_end=epoch_end,\n",
    "        loss_func=loss_func,\n",
    "        save_at=save_at,\n",
    "        is_debug=is_debug,\n",
    "        early_stopping={\n",
    "                'patient': PATIENT,\n",
    "                'criteria': float(\"-inf\"),\n",
    "                'beat_epoch': 0,\n",
    "                'rule': \"max\"\n",
    "            },\n",
    "        device=device,\n",
    "        threshold=threshold,\n",
    "        reset_patient=True,\n",
    "        freeze=False,\n",
    "        do_save_current_stage=True,\n",
    "        compute_loss_with_msk=True,\n",
    "        return_performance=True,\n",
    "        piece_name='',\n",
    "        class_weight=class_weight,\n",
    "        class_count=class_count\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d59d37",
   "metadata": {},
   "source": [
    "## Train on Orchestration dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79693d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty table to store performance for each epoch\n",
    "performance = pd.DataFrame(\n",
    "    columns=['epoch', 'train_acc_l', 'test_acc_l', 'train_acc_d', 'test_acc_d', \n",
    "    'train_precision_mel', 'train_recall_mel', 'test_precision_mel', 'test_recall_mel',\n",
    "    'train_precision_rhythm', 'train_recall_rhythm', 'test_precision_rhythm', 'test_recall_rhythm',\n",
    "    'train_precision_harm', 'train_recall_harm', 'test_precision_harm', 'test_recall_harm']\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "best_epoch = [int(_.split('-best.pt')[0].split('epoch')[-1]) for _ in os.listdir(os.path.join(save_at, 'model')) if _.endswith('best.pt')]\n",
    "all_epoch = [int(_.split('.pt')[0].split('-best')[0].split('epoch')[-1]) for _ in os.listdir(os.path.join(save_at, 'model')) if _.endswith('.pt')]\n",
    "if best_epoch:\n",
    "    best_epoch = max(best_epoch)\n",
    "elif all_epoch:\n",
    "    best_epoch = max(all_epoch)\n",
    "else:\n",
    "    best_epoch = None\n",
    "if best_epoch is not None:\n",
    "    model.load_state_dict(torch.load(os.path.join(\n",
    "        save_at, 'model', f\"epoch{str(best_epoch)}-best.pt\"\n",
    "    )))\n",
    "    epoch_beg = max(epoch_beg, best_epoch)\n",
    "\n",
    "# Record training time \n",
    "time_spend = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c00c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epoch_beg, epoch_end):\n",
    "    print('*'*10, f'Epoch {epoch:4d}', '*'*10)\n",
    "    trainer.epoch = epoch\n",
    "    \n",
    "    t2 = time.time()\n",
    "    current_train_loss, current_train_acc, _train_performance, train_info_dict = trainer.train(train_loader, epoch)\n",
    "    \n",
    "    t3 = time.time()\n",
    "    current_valid_loss, current_valid_acc, _valid_performance, valid_info_dict = trainer.valid(valid_loader, epoch)\n",
    "    t4 = time.time()\n",
    "    current_test_loss, current_test_acc, _test_performance, test_info_dict = trainer.test(test_loader, epoch)\n",
    "\n",
    "    # record time spend\n",
    "    t5 = time.time()\n",
    "    time_spend.append(f'Epoch {epoch} spends {datetime.timedelta(seconds=t5-t2)}: training {datetime.timedelta(seconds=t3-t2)}, validing {datetime.timedelta(seconds=t4-t3)}, testing {datetime.timedelta(seconds=t5-t4)}\\n')\n",
    "    t1 = time.time()\n",
    "    time_spend.append(f'\\n\\nRunning all code: {datetime.timedelta(seconds=t1-t0)}')\n",
    "    with open(os.path.join(save_at, 'time_spend.txt'), 'w') as f:\n",
    "        f.write('\\n'.join(time_spend))\n",
    "\n",
    "    # save model\n",
    "    trainer.check_early_stop(current_valid_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ec55f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_spend = []\n",
    "t0 = time.time()\n",
    "\n",
    "performance = pd.DataFrame(\n",
    "    columns=['epoch', 'train_acc_l', 'test_acc_l', 'train_acc_d', 'test_acc_d', \n",
    "    'train_precision_mel', 'train_recall_mel', 'test_precision_mel', 'test_recall_mel',\n",
    "    'train_precision_rhythm', 'train_recall_rhythm', 'test_precision_rhythm', 'test_recall_rhythm',\n",
    "    'train_precision_harm', 'train_recall_harm', 'test_precision_harm', 'test_recall_harm']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441049c6",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400c696d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, load the best model and test on each mvt \n",
    "best_epoch = [int(_.split('-best.pt')[0].split('epoch')[-1]) for _ in os.listdir(os.path.join(save_at, 'model')) if _.endswith('best.pt')]\n",
    "if best_epoch:\n",
    "    best_epoch = max(best_epoch)\n",
    "else:\n",
    "    best_epoch = epoch_end - 1\n",
    "model.load_state_dict(torch.load(os.path.join(\n",
    "    save_at, 'model', f\"epoch{str(best_epoch)}-best.pt\"\n",
    ")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad95e4c4",
   "metadata": {},
   "source": [
    "### Evaluating on orchestration dataset (test set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21191993",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{save_at}/test_on/confusion_matrix', exist_ok=True)\n",
    "tester = MySingleClassTrainer(\n",
    "    model = model,\n",
    "    optimizer=optimizer, \n",
    "    scheduler=None,\n",
    "    epoch_beg=epoch_beg,\n",
    "    epoch_end=epoch_end, \n",
    "    loss_func=loss_func,\n",
    "    save_at=save_at, \n",
    "    is_debug=is_debug, \n",
    "    early_stopping=trainer.early_stopping,\n",
    "    device=device, threshold=threshold, \n",
    "    freeze=True,\n",
    "    do_save_current_stage=False,\n",
    "    return_performance=True\n",
    ")\n",
    "result = []\n",
    "for apdx in range(18):\n",
    "    test_on_set = PianoRollsDataset(\n",
    "        meta_csv_file,\n",
    "        test=True,\n",
    "        test_piece=[apdx],\n",
    "        context=CONTEXT_MEASURES,\n",
    "        other_inst=OTHER_INST,\n",
    "        blend=BLEND_MODE,\n",
    "        k=k,\n",
    "        add_inst=add_inst,\n",
    "        add_barlines=add_barlines,\n",
    "        add_beats=add_beats,\n",
    "        add_rest=add_rest,\n",
    "        add_replaymtx=add_replaymtx,\n",
    "        converted_path=converted_path,\n",
    "        ds='orchestration',\n",
    "    )\n",
    "    test_on_loader = DataLoader(test_on_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    tester.piece_name = apdx\n",
    "    class_count, class_weight = get_class_weight_for_perf(test_on_set)\n",
    "    tester.class_count = class_count\n",
    "    tester.class_weight = class_weight\n",
    "    for x,y in test_on_loader: break\n",
    "    tester.model.eval()\n",
    "    _,_,performance, _ = tester.test(test_on_loader, epoch=0)\n",
    "    performance.update({'piece_name': apdx})\n",
    "    performance.update({'stage': 'train' if apdx in test_pieces_idx else 'test'})\n",
    "    result.append(performance)\n",
    "    performance['cm_texture_new'] = performance['cm_texture'] / performance['cm_texture'].sum(axis=1, keepdims=True)\n",
    "    print_confusion_matrix(performance['cm_texture_new'], \n",
    "                        f\"{apdx}_texture\",\n",
    "                        f'{save_at}/test_on', show=False)\n",
    "    np.save(f\"{save_at}/test_on/orch-{apdx}.npy\", performance['cm_texture_new'])\n",
    "tmp_df = pd.DataFrame(result)[PERFORMANCE_DF_COLS]\n",
    "tmp_df.to_csv(f'{save_at}/test_on/orch_performance.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e870d731",
   "metadata": {},
   "source": [
    "### Test on S3 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c9b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{save_at}/test_on/confusion_matrix', exist_ok=True)\n",
    "tester = MySingleClassTrainer(\n",
    "    model = model,\n",
    "    optimizer=optimizer, \n",
    "    scheduler=None,\n",
    "    epoch_beg=epoch_beg,\n",
    "    epoch_end=epoch_end, \n",
    "    loss_func=loss_func,\n",
    "    save_at=save_at, \n",
    "    is_debug=is_debug, \n",
    "    early_stopping=trainer.early_stopping,\n",
    "    device=device, threshold=threshold, \n",
    "    freeze=True,\n",
    "    do_save_current_stage=False,\n",
    "    return_performance=True\n",
    ")\n",
    "\n",
    "result = []\n",
    "test_on_set = PianoRollsDataset(\n",
    "    meta_csv_file_s3,\n",
    "    test=True,\n",
    "    test_piece=list(range(16)),\n",
    "    context=CONTEXT_MEASURES,\n",
    "    other_inst=OTHER_INST,\n",
    "    blend=BLEND_MODE,\n",
    "    k=k,\n",
    "    add_inst=add_inst,\n",
    "    add_barlines=add_barlines,\n",
    "    add_replaymtx=add_replaymtx,\n",
    "    converted_path=converted_path,\n",
    "    ds='s3',\n",
    ")\n",
    "test_on_loader = DataLoader(test_on_set, batch_size=BATCH_SIZE, shuffle=False)\n",
    "# tester.piece_name = apdx\n",
    "class_count, class_weight = get_class_weight(test_on_set)\n",
    "tester.class_count = class_count\n",
    "tester.class_weight = class_weight\n",
    "for x,y in test_on_loader: break\n",
    "tester.model.eval()\n",
    "_,_,performance, _ = tester.test(test_on_loader, epoch=0)\n",
    "performance.update({'piece_name': 's3_all'})\n",
    "performance.update({'stage': 'test'})\n",
    "result.append(performance)\n",
    "performance['cm_texture_new'] = performance['cm_texture'] / performance['cm_texture'].sum(axis=1, keepdims=True)\n",
    "print_confusion_matrix(performance['cm_texture_new'], \n",
    "                    f\"s3_all_texture\",\n",
    "                    f'{save_at}/test_on', show=False)\n",
    "np.save(f\"{save_at}/test_on/s3_all.npy\", performance['cm_texture_new'])\n",
    "tmp_df = pd.DataFrame(result)[PERFORMANCE_DF_COLS]\n",
    "tmp_df.to_csv(f'{save_at}/test_on/s3_performance_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d4a891",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
